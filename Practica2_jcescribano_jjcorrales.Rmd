---
title: "Práctica 2: ¿Cómo realizar la limpieza y análisis de datos? "
author: "Juan Carlos Escribano Rubio, Juan Javier Corrales Pérez"
date: "22 de Diciembre de 2022"
output:
  pdf_document:
    df_print: kable
    toc: yes
    toc_depth: 3
lang: es
encoding: "utf-8"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Realizamos la carga de las librerías necesarias
library(gridExtra)
library(car)
library(nortest)
library(VIM)
library(caret)
library(pROC)
library(dplyr)
```
\newpage

# 1. Descripción del dataset.

Para realizar la práctica hemos decidido utilizar el dataset propuesto en el enunciado:

https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset


El nombre del dataset es "Heart Attack Analysis & Prediction Dataset" y contiene diversas variables con información médica de diversos pacientes y la variable "output" dicotómica que indica si tiene más o menos probabilidad de sufrir un ataque cardíaco.

Este dataset nos permite realizar el análisis de diversos datos médicos que pueden ser relevantes a la predicción de la probabilidad de sufrir un ataque cardíaco. Con estos datos estudiaremos la relevancia que tienen algunas variables básicas como la edad y el sexo y construiremos un modelo para determinar la viabilidad de construir un modelo predictivo.

El detalle de las variables contenidas en el dataset es el siguiente:

* age: Edad del paciente.

* sex: Sexo biológico del paciente (0,1)

* cp: Tipo de dolor torácico, medida en cuatro categorías: (0:Angina típica, 1:Angina atípica, 2:Dolor no anginoso, 3:Asintomático)

* trtbps - Presión arterial en reposo (en mm Hg)

* chol - Colesterol en mg/dl obtenido a través del sensor BMI

* fbs - azúcar en sangre en ayunas > 120 mg/dl, medida en dos categorías: (0:Falso, 1:Verdadero)

* restecg - Resultados electrocardiográficos en reposo, medida en tres categorías: (0:Normal, 1:Normalidad de onda ST-T, 2:Hipertrofia ventricular izquierda)

* thalachh - Frecuencia cardíaca máxima alcanzada.

* exng - Angina inducida por el ejercicio, medida en dos categorías: (0:No, 1:Sí)

* oldpeak - Depresión del segmento ST en prueba de esfuerzo

* slp - Pendiente del segmento ST, medida en tres categorías: (0:Pendiente ascendente, 1:Pendiente plana, 2:Pendiente descendente)

* caa - Número de vasos

* thall - Resultado de la prueba de esfuerzo con talio, medida en cuatro categorías: (0 ~ 3)

* output - variable de destino, medida en dos categorías: (0:Menos posibilidades de ataque al corazón, 1:Más posibilidades de ataque al corazón)

Este dataset nos permite, por un lado, realizar un análisis de cuáles son las variables más relevantes de cara a predecir un ataque cardíaco y por otra modelar un sistema predictivo que nos indique la probabilidad de sufrir un ataque cardíaco en base a las variables medicas de un paciente.

# 2. Integración y selección

```{r load}
# Realizamos la carga de los datos a trabajar.
data_heart <- read.csv("heart.csv", stringsAsFactors = TRUE, header = TRUE, sep=",")

# Mostramos las dimensiones, la estructura y el contenido del data frame cargado.
dim(data_heart)
str(data_heart)
summary(data_heart)

# Cambiamos el tipo de datos a factor de algunas variables.
cols<-c("sex","cp","fbs","restecg", "exng", "slp", "thall", "output")
for (i in cols){
data_heart[,i] <- as.factor(data_heart[,i])
}

# Después de los cambios, analizamos la nueva estructura del conjunto de datos
str(data_heart)
```

Dado que todas las variables han sido importadas como tipo __int__, modificamos el tipo de variable a __factor__ para todas las variables categóricas de nuestro dataset.

# 3. Limpieza de los datos.

## 3.1 ¿Los datos contienen ceros o elementos vacíos?

```{r limpieza}
# Estadísticas de valores vacíos
colSums(is.na(data_heart))

# Se comprueba si existen registros duplicados
data_heart[duplicated(data_heart), ]

# Se eliminan los datos duplicados
data_heart <- data_heart[!duplicated(data_heart), ]
```

Se realiza la comprobación de si existen valores vacíos y se comprueba que no existe ninguno. El dataset tampoco contiene datos a cero, ya que todos los datos importados con este valor son correctos.

Se comprueba también de si existen datos duplicados. Se detecta de que existe un registro duplicado y se procede a su eliminación del dataset.

## 3.2 Identifica y gestiona los valores extremos.

```{r fig.height = 3, fig.width = 4}
# Comprobación de age
boxplot(data_heart$age, main="age")

# Comprobación de trtbps
boxplot(data_heart$trtbps, main="trtbps")
x <- boxplot.stats(data_heart$trtbps)$out
idx <- which(data_heart$trtbps %in% x)
sort(data_heart$trtbps[idx])

# Comprobación de chol
boxplot(data_heart$chol, main="chol")
x <- boxplot.stats(data_heart$chol)$out
idx <- which(data_heart$chol %in% x)
sort(data_heart$chol[idx])

# Comprobación de thalachh
boxplot(data_heart$thalachh, main="thalachh")
x <- boxplot.stats(data_heart$thalachh)$out
idx <- which(data_heart$thalachh %in% x)
sort(data_heart$thalachh[idx])

# Comprobación de oldpeak
boxplot(data_heart$oldpeak, main="oldpeak")
x <- boxplot.stats(data_heart$oldpeak)$out
idx <- which(data_heart$oldpeak %in% x)
sort(data_heart$oldpeak[idx])
```

De las variables analizadas, solo se detecta que existen valores extremos en la variable __chol__. En el resto de variables, a pesar de que existen valores atípicos, estos no se consideran valores anómalos.

```{r extremos_correccion}
# chol
# Se asigna a NA los valores > 500. El resto se deja igual.
data_heart$chol[data_heart$chol > 500 ] <- NA

#Check
sum(is.na(data_heart$chol))

# Se calcula la media aritmética por género
idx <- which(is.na(data_heart$chol))
mean.f <- round(mean(data_heart$chol[data_heart$sex == 0], na.rm=TRUE ))
mean.m <- round(mean(data_heart$chol[data_heart$sex == 1], na.rm=TRUE ))

# Se asignan los nuevos valores
data_heart$chol[idx] <- ifelse(data_heart$sex[idx] == 0, mean.f, mean.m)
data_heart$chol[idx]
```

Se corrigen los valores extremos de la variable __chol__ aplicando la imputación de su nuevo valor por la media aritmética de los registros del mismo género, es decir, separado por género.

# 4. Análisis de los datos.

## 4.1 Selección de los grupos de datos que se quieren analizar/comparar 

A continuación indico las preguntas que se quieren responder, las variables que utilizaremos para ello y el tipo de análisis que se realizará en cada caso:

* ¿Tiene influencia el sexo en la probabilidad de tener un ataque cardíaco?
  *  Variables analizadas:
    * sex
    * output
  * Tipo de análisis
    * Indendencia de dos variables categóricas
      * Tabla de contingencia
      * Chi cuadrado
* ¿La edad de las personas con más probabilidad de ataque cardíaco es significativamente diferente de las que tienen menos probabilidad?
  *  Variables analizadas:
    * age
    * output
  * Tipo de análisis
    * Tabla de contingencia
    * Chi cuadrado

* Creación de un modelo de regresión logística
  * Variables analizadas:
    * output -> age, sex, cp, trtbps, thalachh, exng, oldpeak, caa
  * Tipo de análisis:
    * Correlación entras las variables independientes
    * Creación del modelo de regresión
    * Evaluación de la calidad del modelo

## 4.2 Comprobación de la normalidad y homogeneidad de la varianza.

### Comprobación de la normalidad
A continuación comprobaremos la normalidad de las variables que vamos a analizar

#### Edad

* Un qqplot donde observamos que la curva se ajusta bastante bien a la normal
* Un test de Kolmogorov-Smirnov donde obtenemos un p-value>0.05 por lo que podemos
considerar la variable como normal

```{r fig.height = 3, fig.width = 4}
qqnorm(data_heart$age)
qqline(data_heart$age, col=2)
ks.test(data_heart$age, pnorm, mean(data_heart$age), sd(data_heart$age))
```
#### trtbps

* Un qqplot donde observamos que la curva no se ajusta a la normal
* Un test de Kolmogorov-Smirnov donde obtenemos un p-value < 0.05 por lo que podemos
considerar la variable como no normal
* Un test de Shapiro-Wilk donde obtenemos un p-value < 0.05 por lo que podemos
considerar la variable como no normal

```{r fig.height = 3, fig.width = 4}
qqnorm(data_heart$trtbps)
qqline(data_heart$trtbps, col=2)
ks.test(data_heart$trtbps, pnorm, mean(data_heart$trtbps), sd(data_heart$trtbps))
shapiro.test(data_heart$trtbps)
```
#### chol
* Un qqplot donde observamos que la curva se ajusta bastante bien a la normal
* Un test de Kolmogorov-Smirnov donde obtenemos un p-value > 0.05 por lo que podemos
considerar la variable como normal
* Un test de Shapiro-Wilk donde obtenemos un p-value < 0.05 por lo que podemos
considerar la variable como no normal

Dado que tanto en el qqplot como en el test de Kolmogorov-Smirnov se observa normalidad consideraremos la variable como normal

```{r fig.height = 3, fig.width = 4}
qqnorm(data_heart$chol)
qqline(data_heart$chol, col=2)
ks.test(data_heart$chol, pnorm, mean(data_heart$chol), sd(data_heart$chol))
shapiro.test(data_heart$chol)
```


### Comprobación de la homogeneidad de la varianza

#### age

No existe homogeneidad de la varianza entre edad y output (p-value<0.05)
```{r homoage}
leveneTest(age ~ output, data=data_heart)
```
#### trtbps

Existe homogeneidad de la varianza entre trtbps y output (p-value>0.05)

```{r homotrtbps}
leveneTest(trtbps ~ output, data=data_heart)
```
#### chol

Existe homogeneidad de la varianza entre chol y output (p-value>0.05)

```{r homochol}
leveneTest(chol ~ output, data=data_heart)
```
#### sex

No existe homogeneidad de la varianza entre sex y output (p-value<0.05)

```{r homosex}
data_heart$sex_num <- as.numeric(data_heart$sex)
leveneTest(sex_num ~ output, data=data_heart)
```


## 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos. 

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### ¿Tiene influencia el sexo en la probabilidad de tener un ataque cardíaco?

Para responder a esta pregunta realizaremos un test de independencia para dos variables categóricas.

Como primer paso calculamos la tabla de contingencia y representamos sus valores en un gráfico de
barras. 

Tanto en la tabla como en él gráfico observamos diferencias en los valores para cada sexo y que parece
existir alguna relación entre ambas, para comprobar si estas diferencias son estadísticamente significativas realizamos
la prueba de chi cuadrado.

Como resultado del test chi-cuadrado obtenemos un p-value<0.05 lo que significa que existe una diferencia significativa en la distribución entre los sexos con respecto a la probabilidad de tener un ataque cardíaco.


```{r fig.height = 3, fig.width = 5}
tabla_contingencia <- table(data_heart$sex, data_heart$output)

table(data_heart$sex[data_heart$output == 1])
rownames(tabla_contingencia) <- c("Sex 0","Sex 1")
colnames(tabla_contingencia) <- c("Menos probabilidad","Más probabilidad")
print(tabla_contingencia)
barplot(tabla_contingencia, legend = TRUE)
chisq.test(tabla_contingencia)
nrow(subset(data_heart, sex == 1 & output == 0))
```


### ¿La edad de las personas con más probabilidad de ataque cardíaco es significativamente diferente de las que tienen menos probabilidad?

Para responder a esta pregunta realizaremos un contraste de hipótesis para comprobar si la media de edad en el grupo con más probabilidad de ataque cardíaco es diferente del grupo con menos probabilidad.

Como primer paso, se incluyen un histograma para la población de la muestra con más probabilidad de ataque cardíaco y otra con la que tiene menos a efectos de observar las diferencias en la distribución de edades. Observando estos histogramos observamos que la distribución es diferente.

Para realizar el contraste de hipotesis y ya que no existe homogeneidad en la varianza entre age y output, se tiene que pasar el parámetro var.equal = False a la función t.test (así utilizará el t-test de Welch) para que lo tenga en cuenta.

El resultado del test indica que es muy poco probable que la diferencia observada en la media de la edad entre los dos grupos sea debido al azar. Por lo tanto, se puede concluir que hay una diferencia significativa en la edad entre los dos grupos.



```{r fig.height = 3, fig.width = 4}
mas_probabilidad <- subset(data_heart, output == 1)
menos_probabilidad <- subset(data_heart, output == 0)
hist(mas_probabilidad$age,breaks=20)
hist(menos_probabilidad$age,breaks=20)
t.test(data_heart$age ~ data_heart$output,var.equal = FALSE)
```

### Creación de un modelo de regresión logística

```{r regresionlogistica}
# Generamos los datos de entrenamiento y test para el modelo
set.seed(123)
ind <- sample(seq_len(nrow(data_heart)), size = round(.8 * dim(data_heart)[1]))
training <- data_heart[ind, ]
testing <- data_heart[-ind, ]

# Estimamos el modelo
model.logist1=glm(formula=output~age+sex+cp+trtbps+thalachh+exng+oldpeak+caa,data=training, family=binomial)
summary(model.logist1)
```

Observamos que la variable age no es significativa, por lo que procedemos a eliminarla del modelo.\

```{r regresionlogistica2}
model.logist2=glm(formula=output~sex+cp+trtbps+thalachh+exng+oldpeak+caa,data=training, family=binomial)
summary(model.logist2)
vif(model.logist2)
```

Vemos que ahora todas las variables son significativas y que no existe colinealidad.\

```{r confusion}
pred_test <- predict(object = model.logist2, newdata = testing, type = "response")

## Predicción
testing$prediction <- ifelse(pred_test < 0.5 ,0, 1)
prediction <- as.factor(testing$prediction)
true <- testing$output
glimpse(testing[,c(14,16)])

# Matriz confusión
confusionMatrix(prediction, true, positive="1")
```

Una de las métricas que se pueden usar para evaluar el modelo es la exactitud (accuracy), que es la
proporción entre las predicciones correctas hechas por el modelo y el total de predicciones.
En nuestro caso se obtiene un valor de 0.7667 con un intervalo de confianza de (0.6396, 0.8662).

Por otro lado:

• La sensibilidad (sensitivity): 0.9375. Proporción de casos positivos correctamente clasificados.

• La especificidad (specificity): 0.5714. Proporción de casos negativos correctamente clasificados.

A la vista de estos resultados, se puede concluir que es un buen modelo.\

```{r bondad}
# Realizamos el test de Chi-cuadrado
dev <- model.logist2$deviance
nullDev <- model.logist2$null.deviance
Chi_Obs <- nullDev - dev
Chi_Obs

# Calculamos la probabilidad asociada al estadístico del contraste
gl <- model.logist2$df.null - model.logist2$df.residual
chi_prob <- 1 - pchisq(Chi_Obs,gl)
chi_prob
```

A la vista de los resultados el ajuste es bueno con un p-value de 0.\

```{r curvaRoc}
# Se realiza el dibujo de la curva ROC
prob_low = predict(model.logist2, training, type="response")
r = roc(training$output, prob_low, data=training)
plot(r)

value.auc <- auc(r)
value.auc
```
El área por debajo de esa curva toma el valor de 0.921, por lo que la habilidad del modelo para predecir es muy buena.


# 6. Resolución del problema.

Dado el problema que planteabamos consistente en por un lado, analizar algunas de las variables de cara a determinar si tienen influencia en la probabilidad y por otro crear un modelo predictivo con el fin de evaluar su calidad, hemos llegado a las siguientes conclusiones:

* Existen diferencias significativas entre la distribución de sexos en la probabilidad de sufrir un ataque cardíaco
* Existen diferencias significativas entre las medias de edad de las personas con más y menos probabilidad de sufrir un ataque cardíaco.
* Es posible obtener un modelo de regresión logística que obtenga unos buenos resultados predictivos (Sensibilidad = 0.94, especificidad = 0.57)

Como conclusión del análisis podemos indicar que con el conjunto de datos de entrada que hemos utilizado es viable la creación de modelos predictivos que permiten obtener una estimación de la probabilidad de sufrir un ataque cardíaco del paciente en base a sus datos médicos.

# Tabla de contribuciones
| Contribuciones | Firma |
|----------------|-------|
| Investigación previa | jcescribano, jjcorrales |
| Redaccción de las respuestas  |  jcescribano, jjcorrales |
| Desarrollo del código |  jcescribano, jjcorrales |
| Parcipación en el vídeo |  jcescribano, jjcorrales |



